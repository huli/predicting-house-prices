{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import helper_functions\n",
    "import pandas as pd\n",
    "importlib.reload(helper_functions)\n",
    "from helper_functions import *\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, _transform_one\n",
    "from sklearn.externals.joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining pipeline as in other examples\n",
    "trans_pipeline = Pipeline([\n",
    "    ('impute_numerical', DFTransform(lambda X: fill_numerical_nans(X))),\n",
    "    ('impute_categorical', DFTransform(lambda X: impute_categorical(X))),\n",
    "    ('impute_special_cases', DFTransform(lambda X: impute_special_cases(X))),\n",
    "    ('drop_features', DFTransform(lambda X: drop_features(X))),\n",
    "    ('ordinal_features', DFTransform(lambda X: encode_ordinals(X))),\n",
    "    ('check_nans', DFTransform(lambda X: check_nans(X))),\n",
    "    ('encode_dummies', DFTransform(lambda X: create_dummies(X)))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummies...\n",
      "Starting with input of shape: (1456, 78)\n",
      "Returning output of shape: (1456, 219)\n"
     ]
    }
   ],
   "source": [
    "train_df =  pd.read_csv('data/train.csv')\n",
    "X_train = train_df.drop(['SalePrice','Id'], axis=1)\n",
    "y_train = train_df['SalePrice']\n",
    "X_train, y_train = prepare_inputs(X_train, y_train)\n",
    "\n",
    "X_train = trans_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "import livelossplot as lp\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "\n",
    "# Define the build function for the second estimator\n",
    "def build_nn():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(220, kernel_initializer='normal', activation='relu', input_shape=(219,)))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Compiling the mode\n",
    "    model.compile(loss = 'mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "import livelossplot as lp\n",
    "\n",
    "plot_callback = lp.PlotLossesKeras()\n",
    "callbacks = [plot_callback]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp_regressor', KerasRegressor(build_fn=build_nn, batch_size=5, epochs=1000, callbacks=callbacks, \n",
    "                                     validation_data=(X_test, y_test)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1164 samples, validate on 292 samples\n",
      "Epoch 1/1000\n",
      "  90/1164 [=>............................] - ETA: 4s - loss: 141.4572  "
     ]
    }
   ],
   "source": [
    "model_info = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-score: 0.803177001019\n",
      "RMSE (log): 0.1763120074801511\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(X_test)\n",
    "print_benchmark(y_test, predictions, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
