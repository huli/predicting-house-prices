{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking with multiple regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import helper_functions\n",
    "import pandas as pd\n",
    "importlib.reload(helper_functions)\n",
    "from helper_functions import *\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, _transform_one\n",
    "from sklearn.externals.joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining pipeline as in other examples\n",
    "trans_pipeline = Pipeline([\n",
    "    ('impute_numerical', DFTransform(lambda X: fill_numerical_nans(X))),\n",
    "    ('impute_categorical', DFTransform(lambda X: impute_categorical(X))),\n",
    "    ('impute_special_cases', DFTransform(lambda X: impute_special_cases(X))),\n",
    "    ('drop_features', DFTransform(lambda X: drop_features(X))),\n",
    "    ('ordinal_features', DFTransform(lambda X: encode_ordinals(X))),\n",
    "    ('check_nans', DFTransform(lambda X: check_nans(X))),\n",
    "    ('encode_dummies', DFTransform(lambda X: create_dummies(X)))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummies...\n",
      "Starting with input of shape: (2915, 78)\n",
      "Returning output of shape: (2915, 219)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df =  pd.read_csv('data/train.csv')\n",
    "X_train = train_df.drop(['SalePrice','Id'], axis=1)\n",
    "y_train = train_df['SalePrice']\n",
    "X_test = pd.read_csv('data/test.csv').drop(['Id'], axis=1)\n",
    "X_train, y_train = prepare_inputs(X_train, y_train)\n",
    "\n",
    "# Transforming the input\n",
    "X_combined = pd.concat((X_train, X_test)).reset_index(drop=True) \n",
    "X_tranformed = trans_pipeline.fit_transform(X_combined)\n",
    "\n",
    "# Split the transformed input back\n",
    "X_train_trans = X_tranformed[:X_train.shape[0]] \n",
    "X_test_trans = X_tranformed[X_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_trans, y_train, test_size=.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define first estimator\n",
    "adaboost_estimator = AdaBoostRegressor(base_estimator=Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=42, solver='cholesky', tol=0.001),\n",
    "         learning_rate=.001, loss='linear', n_estimators=100,\n",
    "         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=42, solver='cholesky', tol=0.001),\n",
       "         learning_rate=0.001, loss='linear', n_estimators=100,\n",
       "         random_state=42)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the first estimator on the first subset\n",
    "adaboost_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict with the first estimator on the second subset\n",
    "prediction_adaboost = adaboost_estimator.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Define second regressor\n",
    "lasso_estimator = Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=True, positive=False, precompute=False, random_state=None,\n",
    "   selection='cyclic', tol=0.0001, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the second estimator on the first subset\n",
    "lasso_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the second estimator on the second subset\n",
    "prediction_lasso = lasso_estimator.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def rmse_score(y_t, y_pred):\n",
    "    return math.sqrt(mean_squared_error(y_t, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('robust_scaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('ridge_regression', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='cholesky', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'robust_scaler__with_scaling': [True, False], 'robust_scaler__with_centering': [True, False], 'ridge_regression__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(rmse_score, greater_is_better=False), verbose=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import GridSearchCV   \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "param_dict = {'robust_scaler__with_scaling' : [True, False],\n",
    "              'robust_scaler__with_centering' : [True, False],\n",
    "              'ridge_regression__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "             }\n",
    "     \n",
    "scorer = make_scorer(rmse_score, greater_is_better=False)\n",
    "parameter_estimator = GridSearchCV(Pipeline([\n",
    "        ('robust_scaler', RobustScaler()),\n",
    "        ('ridge_regression', Ridge(solver='cholesky'))\n",
    "            ]), param_dict, scoring=scorer)\n",
    "\n",
    "parameter_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not we define a bagging ensemble for the blending\n",
    "bagging_estimator = parameter_estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('robust_scaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "       with_scaling=True)), ('ridge_regression', Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='cholesky', tol=0.001))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This blender now we train on the predictions of the first layer\n",
    "X_blended = np.column_stack((prediction_lasso, prediction_adaboost))\n",
    "\n",
    "bagging_estimator.fit(X_blended, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we use the stack to make a prediction on unseen data\n",
    "test_prediction_ada = adaboost_estimator.predict(X_test)\n",
    "test_prediction_lasso = lasso_estimator.predict(X_test)\n",
    "\n",
    "X_test_blended = np.column_stack((test_prediction_lasso, test_prediction_ada))\n",
    "y_predicted = bagging_estimator.predict(X_test_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-score: 0.91285090301\n",
      "RMSE (log): 0.11802606038596765\n"
     ]
    }
   ],
   "source": [
    "print_benchmark(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
