{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking with multiple regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import helper_functions\n",
    "import pandas as pd\n",
    "importlib.reload(helper_functions)\n",
    "from helper_functions import *\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, _transform_one\n",
    "from sklearn.externals.joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining pipeline as in other examples\n",
    "trans_pipeline = Pipeline([\n",
    "    ('impute_numerical', DFTransform(lambda X: fill_numerical_nans(X))),\n",
    "    ('impute_categorical', DFTransform(lambda X: impute_categorical(X))),\n",
    "    ('impute_special_cases', DFTransform(lambda X: impute_special_cases(X))),\n",
    "    ('drop_features', DFTransform(lambda X: drop_features(X))),\n",
    "    ('ordinal_features', DFTransform(lambda X: encode_ordinals(X))),\n",
    "    ('check_nans', DFTransform(lambda X: check_nans(X))),\n",
    "    ('encode_dummies', DFTransform(lambda X: create_dummies(X)))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummies...\n",
      "Starting with input of shape: (2915, 78)\n",
      "Returning output of shape: (2915, 219)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df =  pd.read_csv('data/train.csv')\n",
    "X_train = train_df.drop(['SalePrice','Id'], axis=1)\n",
    "y_train = train_df['SalePrice']\n",
    "X_test = pd.read_csv('data/test.csv').drop(['Id'], axis=1)\n",
    "X_train, y_train = prepare_inputs(X_train, y_train)\n",
    "\n",
    "# Transforming the input\n",
    "X_combined = pd.concat((X_train, X_test)).reset_index(drop=True) \n",
    "X_tranformed = trans_pipeline.fit_transform(X_combined)\n",
    "\n",
    "# Split the transformed input back\n",
    "X_train_trans = X_tranformed[:X_train.shape[0]] \n",
    "X_test_trans = X_tranformed[X_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_trans, y_train, test_size=.2, random_state=42)\n",
    "\n",
    "# Split the training set into two subsets for prediction and blending\n",
    "X_train_subset1, X_train_subset2, y_train_subset1, y_train_subset2 = \\\n",
    "                                    train_test_split(X_train, y_train, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define first estimator\n",
    "adaboost_estimator = AdaBoostRegressor(base_estimator=Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=42, solver='cholesky', tol=0.001),\n",
    "         learning_rate=.001, loss='linear', n_estimators=100,\n",
    "         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=42, solver='cholesky', tol=0.001),\n",
       "         learning_rate=0.001, loss='linear', n_estimators=100,\n",
       "         random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the first estimator on the first subset\n",
    "adaboost_estimator.fit(X_train_subset1, y_train_subset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict with the first estimator on the second subset\n",
    "prediction_adaboost = adaboost_estimator.predict(X_train_subset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Define second regressor\n",
    "lasso_estimator = Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=True, positive=False, precompute=False, random_state=None,\n",
    "   selection='cyclic', tol=0.0001, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the second estimator on the first subset\n",
    "lasso_estimator.fit(X_train_subset1, y_train_subset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the second estimator on the second subset\n",
    "prediction_lasso = lasso_estimator.predict(X_train_subset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Not we define a bagging ensemble for the blending\n",
    "bagging_estimator = BaggingRegressor(Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,random_state=42), \n",
    "            n_estimators=500, max_samples=200, bootstrap=True, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=42, solver='auto', tol=0.001),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=200, n_estimators=500, n_jobs=4, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This blender now we train on the predictions of the first layer\n",
    "X_blended = np.column_stack((prediction_nn, prediction_adaboost))\n",
    "\n",
    "bagging_estimator.fit(X_blended, y_train_subset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we use the stack to make a prediction on unseen data\n",
    "test_prediction_ada = adaboost_estimator.predict(X_test)\n",
    "test_prediction_lasso = lasso_estimator.predict(X_test)\n",
    "\n",
    "X_test_blended = np.column_stack((test_prediction_lasso, test_prediction_ada))\n",
    "y_predicted = bagging_estimator.predict(X_test_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-score: 0.864335241262\n",
      "RMSE (log): 0.14637856702473265\n"
     ]
    }
   ],
   "source": [
    "print_benchmark(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
